#!/bin/bash

echo "🔍 Markdown 및 MDX 링크 검사 중..."

# URL의 위치 정보(파일명:라인번호)를 저장할 associative array (Bash 4 이상 필요)
declare -A urlLocations

# find 명령어로 현재 및 하위 디렉터리의 .md, .mdx 파일들을 찾고,
# awk를 사용하여 각 파일에서 Markdown 링크 형식([텍스트](URL))의 URL을 추출함.
# 한 줄에 여러 링크가 포함된 경우도 모두 추출하도록 반복함.
file_count=0
total_files=$(find . -type f \( -iname "*.md" -o -iname "*.mdx" \) | wc -l)

# 파일을 하나씩 확인하면서 URL을 추출
while IFS=: read -r file line url; do
    # URL이 비어있으면 스킵
    if [[ -z "$url" ]]; then
        continue
    fi
    if [[ -n "${urlLocations[$url]}" ]]; then
        urlLocations["$url"]+=", ${file}:${line}"
    else
        urlLocations["$url"]="${file}:${line}"
    fi

    # 진행률 출력
    file_count=$((file_count + 1))
    echo -ne "🔗 검사 중... $file_count/$total_files 파일 검사 중\r"
done < <(
    find . -type f \( -iname "*.md" -o -iname "*.mdx" \) -exec awk '
    {
        remainder = $0;
        while(match(remainder, /\[[^]]+\]\((https?:\/\/[^)]+)\)/, arr)) {
            print FILENAME ":" FNR ":" arr[1];
            remainder = substr(remainder, RSTART + RLENGTH);
        }
    }
    ' {} +
)

echo -e "\n🔗 검사 대상 링크 수: ${#urlLocations[@]}"
echo

# URL 검사: 각 URL에 대해 curl로 HTTP 상태코드를 받아 검사
declare -A errorInfo
for url in "${!urlLocations[@]}"; do
    status=$(curl -o /dev/null -s -w "%{http_code}" "$url")
    if [[ "$status" -ge 200 && "$status" -lt 400 ]]; then
        echo "✅ $url"
    elif [[ "$status" -ne 000 ]]; then  # 상태 코드가 000이 아니면 오류로 처리
        echo "❌ $url (상태 코드: $status)"
        errorInfo["$url"]="$status | 위치: ${urlLocations[$url]}"
    fi
done

# 오류가 발생한 링크 목록 최종 출력
if [ ${#errorInfo[@]} -gt 0 ]; then
    echo
    echo "‼️ 오류가 발생한 링크 목록:"
    echo "────────────────────────────────────────────"
    for url in "${!errorInfo[@]}"; do
        echo "🔗 $url"
        echo "   └─ 상태 코드: ${errorInfo[$url]}"
    done
else
    echo
    echo "모든 링크가 정상입니다!"
fi
