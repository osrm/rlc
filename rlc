#!/bin/bash

echo "🔍 Markdown 및 MDX 링크 검사 중..."

# 링크 위치 저장용 Associative Array
declare -A urlLocations

# 링크 추출
while IFS=: read -r file line url; do
    [[ -z "$url" ]] && continue
    if [[ -n "${urlLocations[$url]}" ]]; then
        urlLocations["$url"]+=", ${file}:${line}"
    else
        urlLocations["$url"]="${file}:${line}"
    fi
done < <(
    find . -type f \( -iname "*.md" -o -iname "*.mdx" \) -exec awk '
    {
        remainder = $0;
        while(match(remainder, /\[[^]]+\]\((https?:\/\/[^)]+)\)/, arr)) {
            print FILENAME ":" FNR ":" arr[1];
            remainder = substr(remainder, RSTART + RLENGTH);
        }
    }
    ' {} +
)

count=${#urlLocations[@]}
echo "🔗 검사 대상 링크 수: $count"
echo

# 임시 결과 파일
tmp_output=$(mktemp)
> "$tmp_output"

# 병렬 실행용 함수
check_url() {
    local url="$1"
    local location="$2"
    local status
    status=$(curl -o /dev/null -s -w "%{http_code}" "$url")

    if [[ "$status" -ge 200 && "$status" -lt 400 ]]; then
        echo "✅ $url" >> "$tmp_output"
    elif [[ "$status" == "429" ]]; then
        echo "⚠️  $url | 429 Too Many Requests (무시됨)" >> "$tmp_output"
    else
        echo "❌ $url | $status | 위치: $location" >> "$tmp_output"
    fi
}

export -f check_url
export tmp_output

# 병렬 검사 (3개씩)
printf "%s\n" "${!urlLocations[@]}" | \
    xargs -P3 -I{} bash -c 'check_url "$@"' _ "{}" "${urlLocations[{}]}"

echo
echo "📄 검사 결과:"
grep -E "^✅|^⚠️" "$tmp_output" | sort
echo

# 오류 링크 출력 (정리된 출력)
errors=$(grep "^❌" "$tmp_output")
if [[ -n "$errors" ]]; then
    echo "‼️ 오류가 발생한 링크 목록:"
    echo "────────────────────────────────────────────"
    while IFS= read -r line; do
        url=$(echo "$line" | cut -d '|' -f1 | sed 's/^❌ //')
        status=$(echo "$line" | cut -d '|' -f2 | xargs)
        location=$(echo "$line" | cut -d '|' -f3- | sed 's/^ 위치: //')
        echo "🔗 $url"
        echo "   └─ 상태 코드: $status"
        echo "   └─ 위치: $location"
        echo
    done <<< "$errors"
else
    echo "모든 링크가 정상입니다!"
fi

# 임시 파일 삭제
rm "$tmp_output"
