#!/bin/bash

echo "🔍 Markdown 및 MDX 파일에서 URL 검사 시작..."

# URL 위치 정보를 저장할 associative array
declare -A urlLocations

# 1. Markdown 및 MDX 파일에서 URL 추출
echo "🔗 파일에서 URL 추출 중..."
find . -type f \( -iname "*.md" -o -iname "*.mdx" \) -exec awk '
{
    remainder = $0;
    while (match(remainder, /\[[^]]+\]\((https?:\/\/[^)]+)\)/, arr)) {
        print FILENAME ":" FNR ":" arr[1]; # 파일명, 라인 번호, URL 출력
        remainder = substr(remainder, RSTART + RLENGTH);
    }
}
' {} + > extracted_links.txt

# URL과 위치 정보를 분리
echo "🔗 추출된 URL 정리 중..."
while IFS=: read -r file line url; do
    if [[ -n "$url" ]]; then
        if [[ -n "${urlLocations[$url]}" ]]; then
            urlLocations["$url"]+=", ${file}:${line}"
        else
            urlLocations["$url"]="${file}:${line}"
        fi
    fi
done < extracted_links.txt

# URL 리스트 생성
echo "🔗 중복 제거된 URL 저장..."
echo "${!urlLocations[@]}" | tr ' ' '\n' > url_list.txt

# 2. URL 검사
echo "🚀 URL 상태 검사 중..."
declare -A errorInfo

# 병렬로 curl을 실행하여 상태 코드 확인 (HTTP 429는 무시)
cat url_list.txt | xargs -P 10 -I {} bash -c '
    status=$(curl -o /dev/null -s -w "%{http_code}" "{}")
    if [[ "$status" -ge 400 && "$status" -ne 429 ]]; then
        echo "❌ {} (상태 코드: $status)"
        echo "{} $status" >> invalid_urls_tmp.txt
    elif [[ "$status" -lt 400 ]]; then
        echo "✅ {}"
    fi
'

# 3. 오류 URL 정리
if [[ -f invalid_urls_tmp.txt ]]; then
    while IFS=' ' read -r url status; do
        errorInfo["$url"]="상태 코드: $status | 위치: ${urlLocations[$url]}"
    done < invalid_urls_tmp.txt
    rm invalid_urls_tmp.txt
fi

# 4. 결과 출력
echo
if [ ${#errorInfo[@]} -gt 0 ]; then
    echo "‼️ 유효하지 않은 URL 목록:"
    echo "────────────────────────────────────────────"
    for url in "${!errorInfo[@]}"; do
        echo "🔗 $url"
        echo "   └─ ${errorInfo[$url]}"
    done
else
    echo "모든 링크가 정상입니다!"
fi

# 임시 파일 삭제
rm extracted_links.txt url_list.txt
